<head>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<link rel="stylesheet" href="./local.css">
</head>

# I. Deep Generative Modeling 

<br>

<center><table class="noBorder">
<tbody>
  <tr>
	<td width="33%" align="center">SQ-VAE</td>
	<td width="33%" align="center">FP-Diff</td>
	<td width="33%" align="center">Adaptive DDRM</td>
  </tr><tr>
	<td width="33%" align="center"><a href="https://proceedings.mlr.press/v162/takida22a.html"><img src="./assets/stub.png"></a></td>
	<td width="33%" align="center"><a href="X"><img src="./assets/stub.png"></a></td>
	<td width="33%" align="center"><a href="X"><img src="./assets/stub.png"></a></td>
  </tr><tr class="description">
    <td width="33%" align="center">
	<a href="https://github.com/sony/sqvae">[code]</a>
	<a href="https://arxiv.org/abs/2205.07547">[arXiv]</a>
	<p> An examplar abstract which describes each research topic</p>
    </td>
    <td width="33%" align="center">
	<a href="X">[code]</a>
	<a href="https://arxiv.org/abs/2210.04296">[arXiv]</a>
	<p> An examplar abstract which describes each research topic</p>
    </td>
    <td width="33%" align="center">
	<a href="X">[code]</a>
	<a href="X">[arXiv]</a>
	<p> An examplar abstract which describes each research topic</p>
    </td>
  </tr>
</tbody>
</table></center>



# II. Music Technologies

<br>

<center><table>
<tbody>
  <tr>
	<td width="33%" align="center">Sound Separation</td>
	<td width="33%" align="center">Sound Separation</td>
	<td width="33%" align="center">MDX21</td>
  </tr><tr>
	<td width="33%" align="center"><a href="https://ieeexplore.ieee.org/document/9746317"><img src="./assets/stub.png"></a></td>
	<td width="33%" align="center"><a href="https://www.youtube.com/watch?v=EWYxJGmw0Ng"><img src="./assets/enoch_arden.jpg"></a></td>
	<td width="33%" align="center"><a href="https://mdx-workshop.github.io/"><img src="./assets/MDX.png"></a></td>
  </tr><tr class="description">
    <td width="33%" align="center">
	<a href="https://ieeexplore.ieee.org/document/9746317">[IEEE]</a>
	<p>Music Source Separation with Deep Equilibrium Models</p>
    </td>
    <td width="33%" align="center">
	<a href="https://www.youtube.com/watch?v=EWYxJGmw0Ng">[video]</a>
	<a href="https://www.sony.com/en/SonyInfo/technology/stories/AI_Sound_Separation/">[site]</a>
	<p>Glenn Gould and Kanji Ishimaru 2021: A collaboration with AI Sound Separation after 60 years</p>
    </td>
    <td width="33%" align="center">
	<a href="https://mdx-workshop.github.io/">[site]</a>
	<a href="https://www.frontiersin.org/articles/10.3389/frsip.2021.808395/full">[article]</a>
	<p>Music Demixing Challenge 2021</p>
    </td>
  </tr>
</tbody>
</table></center>

<center><table>
<tbody>
  <tr>
	<td width="33%" align="center">Singing Voice Vocoder</td>
	<td width="33%" align="center">Singing Voice Conversion</td>
	<td width="33%" align="center">Vocal Dereverberation</td>
  </tr><tr>
	<td width="33%" align="center"><a href="X"><img src="./assets/stub.png"></a></td>
	<td width="33%" align="center"><a href="X"><img src="./assets/stub.png"></a></td>
	<td width="33%" align="center"><a href="X"><img src="./assets/stub.png"></a></td>
  </tr><tr class="description">
    <td width="33%" align="center">
	<a href="https://arxiv.org/abs/2210.07508">[arXiv]</a>
	<a href="https://t-naoya.github.io/hdm/">[demo]</a>
	<p>Hierarchical Diffusion Models for Singing Voice Neural Vocoder</p>
    </td>
    <td width="33%" align="center">
	<a href="https://arxiv.org/abs/2210.11096">[arXiv]</a>
	<a href="https://t-naoya.github.io/rosvc/">[demo]</a>
	<p>Robust One-Shot Singing Voice Conversion</p>
    </td>
    <td width="33%" align="center">
	<a href="https://arxiv.org/abs/2211.04124">[arXiv]</a>
	<a href="https://koichi-saito-sony.github.io/unsupervised-vocal-dereverb/">[demo]</a>
	<p>Unsupervised Vocal Dereverberation with Diffusion-based Generative Models</p>
    </td>
  </tr>
</tbody>
</table></center>

<center><table>
<tbody>
  <tr>
	<td width="33%" align="center">Distortion Effect Removal</td>
	<td width="33%" align="center">Music Transcription</td>
	<td width="33%" align="center">Automatic Music Mixing</td>
  </tr><tr>
	<td width="33%" align="center"><a href="X"><img src="./assets/stub.png"></a></td>
	<td width="33%" align="center"><a href="X"><img src="./assets/stub.png"></a></td>
	<td width="33%" align="center"><a href="X"><img src="./assets/stub.png"></a></td>
  </tr><tr class="description">
    <td width="33%" align="center">
	<a href="https://arxiv.org/abs/2202.01664">[arXiv]</a>
	<a href="https://joimort.github.io/distortionremoval/">[demo]</a>
	<p>Distortion Audio Effects: Learning How to Recover the Clean Signal</p>
    </td>
    <td width="33%" align="center">
	<a href="https://arxiv.org/abs/2210.05148">[arXiv]</a>
	<a href="https://github.com/sony/DiffRoll">[code]</a>
	<a href="https://sony.github.io/DiffRoll/">[demo]</a>
	<p>DiffRoll: Diffusion-based Generative Music Transcription with Unsupervised Pretraining Capability</p>
    </td>
    <td width="33%" align="center">
	<a href="https://arxiv.org/abs/2208.11428">[arXiv]</a>
	<a href="https://github.com/sony/fxnorm-automix">[code]</a>
	<a href="https://marco-martinez-sony.github.io/FxNorm-automix/">[demo]</a>	
	<p>Automatic Music Mixing with Deep Learning and Out-of-Domain Data</p>
    </td>
  </tr>
</tbody>
</table></center>

<center><table>
<tbody>
  <tr>
	<td width="33%" align="center">Mixing Style Transfer</td>
	<td width="33%" align="center">Automatic DJ Transition</td>
	<td width="33%" align="center"></td>
  </tr><tr>
	<td width="33%" align="center"><a href="X"><img src="./assets/stub.png"></a></td>
	<td width="33%" align="center"><a href="X"><img src="./assets/stub.png"></a></td>
	<td width="33%" align="center"><a href="X"><img src="./assets/stub.png"></a></td>
  </tr><tr class="description">
    <td width="33%" align="center">
	<a href="https://arxiv.org/abs/2211.02247">[arXiv]</a>
	<a href="https://github.com/jhtonyKoo/music_mixing_style_transfer">[code]</a>
	<a href="https://jhtonykoo.github.io/MixingStyleTransfer/">[demo]</a>	
	<p>Music Mixing Style Transfer: A Contrastive Learning Approach to Disentangle Audio Effects</p>
    </td>
    <td width="33%" align="center">
	<a href="https://arxiv.org/abs/2110.06525">[arXiv]</a>
	<a href="https://github.com/ChenPaulYu/DJtransGAN">[code]</a>
	<a href="https://paulyuchen.com/djtransgan-icassp2022/">[demo]</a>		
	<p>Automatic DJ Transitions with Differentiable Audio Effects and Generative Adversarial Networks</p>
    </td>
    <td width="33%" align="center">
	<p> </p>
    </td>
  </tr>
</tbody>
</table></center>
